# user-effort-index

How do you know when a user experience isn’t hitting the mark? Do you wait for it to show up in qualitative feedback? Do you have a long list of different metrics that you have to keep track of that could potentially signal a problem? When evaluating user experiences, how can you quantify if it’s a good experience or not? Additionally, how do you know if your good or bad experience is impacting other areas of the business?

These are common problems for product managers and the data scientists and analysts who support them. To solve them, I propose creating an aggregate metric that represents the effort or friction experienced by your users - a User Effort Index.

Creating a useful User Effort Index includes:

Identifying the data that can actually signal a problem (versus creating noise)
Assigning weights to represent how much friction each data point represents for a user
This can be achieved through data exploration and statistical analysis- but should also be informed by your product knowledge.

Once created, you can use a User Effort Index to improve the user experience through EDA, A/B testing, automation, cohort analysis, and more.

My talk goes through the steps of creating a User Effort Index and suggestions for how to use the metric to improve the user experience.

June 2024: presented at [IDEAL Annual Meeting and Industry Day 2024](https://www.ideal-institute.org/2024/05/06/ideal-annual-meeting-and-industry-day-2024/)

December 2024: presented at [PyData Global](https://pydata.org/global2024)
